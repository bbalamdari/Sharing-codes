{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bbalamdari/Sharing-codes/blob/master/Copy_of_blood_cell.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suo5H5MzulD-",
        "outputId": "5bb919a8-740a-4192-c42d-8abe0bcd4f84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/grive; to attempt to forcibly remount, call drive.mount(\"/content/grive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount into drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/grive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2cMSzj3zQjc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPLMshi_zQ5P"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueKl0r-4zU6p"
      },
      "outputs": [],
      "source": [
        "#################skip this part below ###############################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxBHsHlPzUyJ"
      },
      "outputs": [],
      "source": [
        "train_dir = '/content/grive/MyDrive/archive (1)/dataset2-master/dataset2-master/images/TRAIN'\n",
        "test_dir = '/content/grive/MyDrive/archive (1)/dataset2-master/dataset2-master/images/TEST'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQhZdr1xzU9e"
      },
      "outputs": [],
      "source": [
        "# Create generators\n",
        "\n",
        "train_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
        "    validation_split=0\n",
        ")\n",
        "\n",
        "test_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUlpWUi7zVAl",
        "outputId": "d82e40f4-bbfd-46dd-c3ff-b53427139149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9957 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "# Flow image data\n",
        "\n",
        "train_images = train_gen.flow_from_directory(\n",
        "    directory=train_dir,\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    subset='training'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aSlIM6HzVDe",
        "outputId": "3175fa08-0169-4574-8c80-f81d71eed08f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9458 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "val_images = train_gen.flow_from_directory(\n",
        "    directory=train_dir,\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    subset='validation'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3KYd-UszVG1",
        "outputId": "9460bb69-410a-462f-9f0d-8050ff19b500"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2487 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "test_images = test_gen.flow_from_directory(\n",
        "    directory=test_dir,\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vf4bTQ5Uz7Dv"
      },
      "outputs": [],
      "source": [
        "############skip this part above##################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kho7EyaLz8L6"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0aLOAY8HDzi"
      },
      "outputs": [],
      "source": [
        "folder_path = '/content/grive/MyDrive/archive (1)/dataset2-master/dataset2-master/images/TRAIN'\n",
        "labels = ['Eosinophil', 'Lymphocyte', 'Monocyte', 'Neutrophil']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7Xew_J-Oyux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f97d3d47-1486-40ca-b2c0-8e8d8de9b33a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EOSINOPHIL\n",
            "LYMPHOCYTE\n",
            "MONOCYTE\n",
            "NEUTROPHIL\n"
          ]
        }
      ],
      "source": [
        "# give labels to images in each folder using folder name\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "images = []\n",
        "image_labels = []\n",
        "\n",
        "for folder in os.listdir(folder_path):\n",
        "    print(folder)\n",
        "    subfolder_path = os.path.join(folder_path, folder)\n",
        "    if os.path.isdir(subfolder_path):\n",
        "        for filename in os.listdir(subfolder_path):\n",
        "            if filename.endswith('.jpeg') or filename.endswith('.png'):\n",
        "                image_path = os.path.join(subfolder_path, filename)\n",
        "                image = cv2.imread(image_path)\n",
        "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "                label = folder.upper()\n",
        "                images.append(image)\n",
        "                image_labels.append(label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNDLuBwPpKEI",
        "outputId": "fd53a851-6ddd-4c63-a9f3-1d5f121d4ce2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9957"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "len(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzhAiqk-fQcb"
      },
      "outputs": [],
      "source": [
        "# takes too long even on colab. going to make a smaller trainig set for warm up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6C2iDZDEo8_U"
      },
      "outputs": [],
      "source": [
        "# select indecs randomly for 5000 images to be trained on\n",
        "import random\n",
        "\n",
        "# Get the indices of all items in the list\n",
        "all_indices = list(range(len(images)))\n",
        "\n",
        "# Randomly select items along with their indices\n",
        "random_indices = random.sample(all_indices, k=8000)\n",
        "sampled_images = [images[i] for i in random_indices]\n",
        "sampled_labels = [image_labels[i] for i in random_indices]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the not selected indeces for test and validation later\n",
        "not_selected_indices = [i for i in all_indices if i not in random_indices]\n",
        "test_images = [images[i] for i in not_selected_indices]\n",
        "test_labels = [image_labels[i] for i in not_selected_indices]\n"
      ],
      "metadata": {
        "id": "6cQx2uGKH-wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QKhBXES7H2gD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMzn2KgosdF4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHerWIxlkFlE"
      },
      "outputs": [],
      "source": [
        "# change the labels\n",
        "map_label_to_type = {'EOSINOPHIL':1, 'LYMPHOCYTE':2, 'MONOCYTE':3, 'NEUTROPHIL':4}\n",
        "\n",
        "updated_list = [map_label_to_type[value] for value in sampled_labels] # labels for training set\n",
        "\n",
        "test_label_list = [map_label_to_type[value] for value in test_labels] # labels for test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v0RVTVsNBYY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Convert to tensor for training set\n",
        "images_tensor = torch.tensor(sampled_images).float().to(device)\n",
        "labels_tensor = torch.tensor(np.array(updated_list)).int().to(device)\n",
        "\n",
        "# Convert to tensor for test set\n",
        "test_tensor_image = torch.tensor(test_images).float().to(device)\n",
        "test_tensor_label = torch.tensor(np.array(test_label_list)).int().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG5ceVjBBYsH",
        "outputId": "0e914b92-9d92-462a-be98-3cbaef38bd49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-a58a4fcb0fcb>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  images_tensor = torch.tensor(sampled_images).float().to(device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rqDXLvvwBYvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XVjRV5MQm1j"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "\n",
        "# convert to tensor for training set\n",
        "images_tensor = torch.tensor(sampled_images).float()\n",
        "labels_tensor = torch.tensor(np.array(updated_list)).int()\n",
        "\n",
        "# convert to tensor for test set\n",
        "test_tensor_image = torch.tensor(test_images).float()\n",
        "test_tensor_label = torch.tensor(np.array(test_label_list)).int()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save trainig and test sets to save time\n",
        "import h5py\n",
        "\n",
        "# Save image tensor to HDF5 file for future use\n",
        "with h5py.File('images_tensor.h5', 'w') as file:\n",
        "    file.create_dataset('images_tensor', data=images_tensor.numpy())\n",
        "\n",
        "\n",
        "  # Save label tensor to HDF5 file for future use\n",
        "with h5py.File('labels_tensor.h5', 'w') as file:\n",
        "    file.create_dataset('labels_tensor', data=labels_tensor.numpy())\n",
        "\n",
        "\n",
        "# Save image tensor to HDF5 file for future use\n",
        "with h5py.File('test_tensor_image.h5', 'w') as file:\n",
        "    file.create_dataset('test_tensor_image', data=images_tensor.numpy())\n",
        "\n",
        "\n",
        "  # Save label tensor to HDF5 file for future use\n",
        "with h5py.File('test_tensor_label.h5', 'w') as file:\n",
        "    file.create_dataset('test_tensor_label', data=labels_tensor.numpy())"
      ],
      "metadata": {
        "id": "HHBfLlqJSyLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SlBlN5U4XkLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# how read the h5 file#################################"
      ],
      "metadata": {
        "id": "S4tOQkL-GpK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "\n",
        "# Open the HDF5 file in read mode\n",
        "with h5py.File('/content/grive/MyDrive/test_tensor_image.h5', 'r') as file:\n",
        "    # Access the dataset named 'tensor_label'\n",
        "    dataset = file['test_tensor_image']\n",
        "\n",
        "    # Read the data from the dataset into a numpy array\n",
        "    images_array = dataset[()]"
      ],
      "metadata": {
        "id": "ssriy5FGGUJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "\n",
        "# Open the HDF5 file in read mode\n",
        "with h5py.File('/content/grive/MyDrive/test_tensor_label.h5', 'r') as file:\n",
        "    # Access the dataset named 'tensor_label'\n",
        "    dataset = file['test_tensor_label']\n",
        "\n",
        "    # Read the data from the dataset into a numpy array\n",
        "    label_array = dataset[()]"
      ],
      "metadata": {
        "id": "o5Tfk6RbBaAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "\n",
        "# convert to tensor for training set\n",
        "images_tensor = torch.tensor(images_array).float()\n",
        "labels_tensor = torch.tensor(label_array).int()"
      ],
      "metadata": {
        "id": "LQHtQHFZZech"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################################################"
      ],
      "metadata": {
        "id": "nYeTsa7UGp1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpfgQMg6s88H",
        "outputId": "7cc57be8-6eef-4df0-f3bd-a56af512b7b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8000])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "labels_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0g921FfHws2",
        "outputId": "19e296ed-fd35-474d-de3d-7ffec773fb93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8000, 3, 240, 320])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "images_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2e0pXrkOZcBs"
      },
      "outputs": [],
      "source": [
        "# correct shape of tensor otherwise model will fail\n",
        "images_tensor = images_tensor.permute(0, 3, 1, 2) # make sure 3 channels is at the right location."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYQZWRgSuGnD"
      },
      "outputs": [],
      "source": [
        "# run model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### read saved tensors"
      ],
      "metadata": {
        "id": "jt-TROYTZyHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#############"
      ],
      "metadata": {
        "id": "sU0UfcW7ZyZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhDly-QF4yAQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "num_classes = 4\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 80 * 60, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AN0R_HiqBZpY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e13a5774-377b-45e8-9663-184ed3fad857"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyModel(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=2457600, out_features=512, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Dropout(p=0.5, inplace=False)\n",
            "    (9): Linear(in_features=256, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Create a TensorDataset from the images_tensor and labels_tensor\n",
        "dataset = TensorDataset(images_tensor, labels_tensor)\n",
        "\n",
        "# Define the batch size\n",
        "batch_size = 16\n",
        "\n",
        "# Create a DataLoader with the defined batch size\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Create an instance of the model\n",
        "model = MyModel()\n",
        "print(model)\n",
        "# Define the optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Define the number of epochs\n",
        "num_epochs = 4\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cU2XxIZ5xHxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OEMJnBeaxH1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgR3v7PlBdev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36cb09ba-768b-43b7-c7fb-77590669a67c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss: 20.35728411746025\n",
            "Epoch 2: Loss: 1.3974637203216553\n",
            "Epoch 3: Loss: 1.3879003872871398\n",
            "Epoch 4: Loss: 1.3864533948898314\n"
          ]
        }
      ],
      "source": [
        "# Iterate over the epochs\n",
        "for epoch in range(num_epochs):\n",
        "    # Accumulate gradients over multiple batches\n",
        "    total_loss = 0.0\n",
        "    accumulation_steps = 4\n",
        "\n",
        "    for i, (batch_images, batch_labels) in enumerate(data_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Perform forward pass\n",
        "        outputs = model(batch_images)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        batch_labels = batch_labels.long() - 1  # Convert labels to 0-indexed\n",
        "        loss = criterion(outputs, batch_labels)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Perform gradient accumulation\n",
        "        if (i + 1) % accumulation_steps == 0 or (i + 1) == len(data_loader):\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}: Loss: {total_loss / len(data_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_3qCvGH0hGl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "74482146-92dd-46b9-e86c-7d7a6e46bbcd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-65e243f6ecfb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'trained_model.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'trained_model.pth')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Assuming you have a model architecture defined similar to the original model\n",
        "model = MyModel()\n",
        "\n",
        "# Load the saved model state dictionary\n",
        "model.load_state_dict(torch.load('/content/grive/MyDrive/trained_model.pth'))\n",
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "oGU-8yKCtrYi",
        "outputId": "4d08fca5-2c5d-4ec7-a77c-75631d569c9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-e21f31504425>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Assuming you have a model architecture defined similar to the original model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load the saved model state dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MyModel' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKYBl_hgiA8T"
      },
      "outputs": [],
      "source": [
        "#choose random 10 images for test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = images_array\n",
        "labels = label_array"
      ],
      "metadata": {
        "id": "ni9uBdZRv3Pt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZUDgCNv5EfF"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "# Get the indices of all items in the list\n",
        "indices = list(range(len(images)))\n",
        "\n",
        "# Randomly select 10 items along with their indices\n",
        "test_indices = random.sample(indices, k=10)\n",
        "test_images = [images[i] for i in test_indices]\n",
        "test_tensor = torch.tensor(test_images).float()\n",
        "\n",
        "\n",
        "test_labels = [labels[i] for i in test_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmxYExFxGp4N",
        "outputId": "82adb886-44bd-4f79-d4b0-7742668ce765"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 3, 240, 320])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "test_tensor = test_tensor.permute(0, 3, 1, 2)\n",
        "test_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBoEGd4fiIsx"
      },
      "outputs": [],
      "source": [
        "# predict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have new data stored in a variable named 'new_data'\n",
        "predicted_outputs = model(test_tensor)\n",
        "\n",
        "# Process the predicted outputs as needed\n",
        "# ..."
      ],
      "metadata": {
        "id": "C6RcsH4duP4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions\n",
        "predictions = torch.argmax(predicted_outputs, dim=1)\n",
        "\n",
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6alhvTruYIV",
        "outputId": "3d2ab91e-55dc-45e5-ef6d-f2d090ae9118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 0, 0, 0, 3, 3, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YetF8dr61D30",
        "outputId": "bf61ad5a-4dc8-40c8-bbe0-f2a658243a53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 3, 4, 3, 2, 3, 4, 2, 4, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHLC-FASnlEi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "model = MyModel()\n",
        "\n",
        "# model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(test_tensor)\n",
        "\n",
        "# predictions\n",
        "predictions = torch.argmax(outputs, dim=1)\n",
        "\n",
        "\n",
        "print(predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kw4knJqOHbZv",
        "outputId": "7dca79d3-6d98-4a3c-cb58-bd8b288e4d57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 2, 1, 2, 3, 1, 4, 3, 3, 4]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_labels = [image_labels[i] for i in test_indices]\n",
        "map_label_to_type = {'EOSINOPHIL':1, 'LYMPHOCYTE':2, 'MONOCYTE':3, 'NEUTROPHIL':4}\n",
        "\n",
        "updated_test = [map_label_to_type[value] for value in test_labels]\n",
        "updated_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTl5VYPcjLf0"
      },
      "source": [
        "# New Section\n",
        "ignore cells below\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "num_classes = 4\n",
        "batch_size = 16\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(128 * 30 * 40, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Create your data loader and dataset\n",
        "dataset = TensorDataset(images_tensor, labels_tensor)\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Create an instance of your model\n",
        "model = MyModel()\n",
        "\n",
        "# Move the model to GPU if available\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "# Define your loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define your optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Iterate over the epochs\n",
        "for epoch in range(num_epochs):\n",
        "    # Accumulate gradients over multiple batches\n",
        "    total_loss = 0.0\n",
        "    accumulation_steps = 4\n",
        "\n",
        "    for i, (batch_images, batch_labels) in enumerate(data_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Move the batch to GPU if available\n",
        "        if torch.cuda.is_available():\n",
        "            batch_images = batch_images.cuda()\n",
        "            batch_labels = batch_labels.cuda()\n",
        "\n",
        "        # Perform forward pass\n",
        "        outputs = model(batch_images)\n",
        "        loss = criterion(outputs, batch_labels)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Perform gradient accumulation\n",
        "        if (i + 1) % accumulation_steps == 0 or (i + 1) == len(data_loader):\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        # Clear variables explicitly to free up memory\n",
        "        del batch_images, batch_labels, outputs, loss\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}: Loss: {total_loss / len(data_loader)}\")\n"
      ],
      "metadata": {
        "id": "XM6PipaIZafR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptK_d39ui-TH"
      },
      "outputs": [],
      "source": [
        "# basic run mymodel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eDWSTFVf6-8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Create an instance of the model\n",
        "model = MyModel()\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Define the number of epochs\n",
        "num_epochs = 10\n",
        "\n",
        "# Iterate over the epochs\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(images_tensor)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # Calculate the loss\n",
        "    loss = criterion(outputs, labels_tensor.long())\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Update the model's parameters\n",
        "    optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHaaQrK1DON_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjMLy7ygl2e4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Create a TensorDataset from the images_tensor and labels_tensor\n",
        "dataset = TensorDataset(images_tensor, labels_tensor)\n",
        "\n",
        "# Define the batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Create a DataLoader with the defined batch size\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Create an instance of the model\n",
        "model = MyModel()\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Define the number of epochs\n",
        "num_epochs = 10\n",
        "\n",
        "# Iterate over the epochs\n",
        "for epoch in range(num_epochs):\n",
        "    # Iterate over the batches\n",
        "    for batch_images, batch_labels in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(batch_images)\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        # Calculate the loss\n",
        "        loss = criterion(outputs, batch_labels.long())\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the model's parameters\n",
        "        optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rhciZYVOTVw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XNVqiYMLTV2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MUUbdjY3TV49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lbXtn5poTV8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lb6bMchLTV-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "n4w_1zf4RKsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "FX9fJ3BbhjXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "GQJa05UuNnYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount into drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/grive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZUu_KS6hja7",
        "outputId": "a7ca6eff-718d-416a-c188-cbb9aef2028c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/grive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "-oV5K3DUhjdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Swish(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(x)\n",
        "\n",
        "\n",
        "class SpatialPyramidPooling(nn.Module):\n",
        "    def __init__(self, output_sizes):\n",
        "        super(SpatialPyramidPooling, self).__init__()\n",
        "        self.output_sizes = output_sizes\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, channels, height, width = x.size()\n",
        "        pooled_features = []\n",
        "\n",
        "        for output_size in self.output_sizes:\n",
        "            kh, kw = height // output_size, width // output_size\n",
        "            ph, pw = height % output_size, width % output_size\n",
        "\n",
        "            if ph == 0 and pw == 0:\n",
        "                pooled_features.append(F.max_pool2d(x, kernel_size=(kh, kw), stride=(kh, kw)))\n",
        "            else:\n",
        "                x_padded = F.pad(x, (0, pw, 0, ph))\n",
        "                pooled_features.append(F.max_pool2d(x_padded, kernel_size=(kh, kw), stride=(kh, kw)))\n",
        "\n",
        "        x = torch.cat(pooled_features, dim=1)\n",
        "        x = x.view(batch_size, -1)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, dilation=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            Swish(),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, dilation=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            Swish(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, dilation=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            Swish(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, dilation=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            Swish(),\n",
        "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, dilation=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            Swish(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            SpatialPyramidPooling(output_sizes=[4, 4, 4])\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 48, 512),\n",
        "            Swish(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(512, 512),\n",
        "            Swish(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(512, 256),\n",
        "            Swish(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(256, 4)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "5vcdXHzdhjg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply weight initialization\n",
        "def weight_init(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "        nn.init.kaiming_uniform_(m.weight)\n"
      ],
      "metadata": {
        "id": "TjW4w_v8gTYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your model\n",
        "num_classes = 4\n",
        "model = MyModel().to(device)\n",
        "# Initialize the model\n",
        "model.apply(weight_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2j4OrYqvw8YA",
        "outputId": "ada7729a-2716-4eda-cd04-144caa513966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyModel(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): Swish()\n",
              "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): Swish()\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): Swish()\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): Swish()\n",
              "    (13): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (15): Swish()\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): SpatialPyramidPooling()\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=24576, out_features=512, bias=True)\n",
              "    (1): Swish()\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (4): Swish()\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (7): Swish()\n",
              "    (8): Dropout(p=0.5, inplace=False)\n",
              "    (9): Linear(in_features=256, out_features=4, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define the directory path and image transformations\n",
        "train_directory = '/content/grive/MyDrive/archive (1)/dataset2-master/dataset2-master/images/TRAIN'\n",
        "image_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Create the ImageFolder dataset\n",
        "train_dataset = ImageFolder(train_directory, transform=image_transforms)\n",
        "\n",
        "import random\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "# Define the number of images to sample\n",
        "n = 9900\n",
        "\n",
        "# Get the total number of images in the dataset\n",
        "total_images = len(train_dataset)\n",
        "\n",
        "# Generate random indices to sample from the dataset\n",
        "random_indices = random.sample(range(total_images), n)\n",
        "\n",
        "# Create a Subset of the dataset with the randomly sampled indices\n",
        "sampled_dataset = Subset(train_dataset, random_indices)\n",
        "\n",
        "# Create the DataLoader\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader for the sampled dataset\n",
        "train_loader = DataLoader(sampled_dataset, batch_size=batch_size, shuffle=True)\n"
      ],
      "metadata": {
        "id": "osvIOkSwz1Kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import time\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Move the criterion to the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "# Move the model to the appropriate device\n",
        "model = model.to(device)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "best_loss = float('inf')\n",
        "patience = 10\n",
        "counter = 0\n",
        "\n",
        "# Create the learning rate scheduler\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
        "\n",
        "start = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    # Accumulate gradients over multiple batches\n",
        "    total_loss = 0.0\n",
        "    accumulation_steps = 4\n",
        "\n",
        "    for i, (batch_images, batch_labels) in enumerate(train_loader):\n",
        "        batch_images = batch_images.to(device)  # Send the input tensor to the appropriate device\n",
        "        batch_labels = batch_labels.to(device)  # Send the input tensor to the appropriate device\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Perform forward pass\n",
        "        outputs = model(batch_images)\n",
        "        loss = criterion(outputs, batch_labels)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Perform gradient accumulation\n",
        "        if (i + 1) % accumulation_steps == 0 or (i + 1) == len(train_loader):\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "    total_loss /= len(train_loader)\n",
        "\n",
        "    # Print epoch information\n",
        "    print(f\"Epoch {epoch + 1}: Loss: {total_loss}\")\n",
        "\n",
        "    # Update the learning rate scheduler\n",
        "    scheduler.step(total_loss)\n",
        "\n",
        "    # Check for early stopping\n",
        "    if total_loss < best_loss:\n",
        "        best_loss = total_loss\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "        if counter >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "end = time.time()\n",
        "print(f\"Training time: {end - start}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3Yi1DIiX9mT",
        "outputId": "9f6e4737-0ff4-4835-8d2b-6bd85c2bdc21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss: 16.042223346637794\n",
            "Epoch 2: Loss: 1.3929076254464121\n",
            "Epoch 3: Loss: 1.3877595270199998\n",
            "Epoch 4: Loss: 1.3899815540899174\n",
            "Epoch 5: Loss: 1.3877947340104038\n",
            "Epoch 6: Loss: 1.3880004896293356\n",
            "Epoch 7: Loss: 1.3883157417731833\n",
            "Epoch 8: Loss: 1.388179498650916\n",
            "Epoch 9: Loss: 1.3873445105668223\n",
            "Epoch 10: Loss: 1.3876047099734354\n",
            "Training time: 4686.342383623123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/grive/MyDrive/model_objects/model_4_10000.pht')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "Ybo__ZgubZeB",
        "outputId": "9642501d-e4fa-4289-fd79-d86a1cae8b37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a7bb38eb1895>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/grive/MyDrive/model_objects/model_4_10000.pht'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "model_upload = torch.load('/content/grive/MyDrive/model_objects/model_4_10000.pht', map_location=device)\n",
        "\n",
        "# Create an instance of MyModel\n",
        "model = MyModel()\n",
        "\n",
        "# Copy the loaded weights and biases to the model\n",
        "model.load_state_dict(model_upload)\n",
        "\n",
        "# Move the model to the appropriate device\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "P_WUxwzk4Wep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.math_ops import truncate_div\n",
        "appended_preds = torch.tensor([]).to(device)\n",
        "appended_true = torch.tensor([]).to(device)\n",
        "\n",
        "# Predict on the test set\n",
        "with torch.no_grad():\n",
        "    for batch_images, batch_labels in train_loader:\n",
        "        batch_images = batch_images.to(device)\n",
        "        outputs = model(batch_images)\n",
        "        softmax = nn.Softmax(dim=1)\n",
        "        probabilities = softmax(outputs)\n",
        "        _, predicted_indices = torch.max(probabilities, dim=1)\n",
        "        appended_preds = torch.cat((appended_preds, predicted_indices), dim=0)\n",
        "        appended_true = torch.cat((appended_true, batch_labels.to(device)), dim=0)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qvYMiy-Em8Gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "appended_true.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OX2-LVILtnL",
        "outputId": "2cf2738c-3310-4fb3-8413-685bf207de2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([9900])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#plt.plot(appended_preds.cpu().numpy())\n",
        "#plt.plot(appended_true.cpu().numpy())\n",
        "plt.scatter(appended_preds.cpu().numpy(), appended_true.cpu().numpy())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "o_iqy9CLPTww",
        "outputId": "5e43a5d8-1c98-475b-bd1c-5619c9f01f9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f6658ef3a60>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total = len(appended_true)\n",
        "correct = (appended_preds == appended_true).sum().item()\n",
        "accuracy = correct / total * 100\n",
        "\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyIkKHtoP8ep",
        "outputId": "1969910d-1c33-49fd-eb41-74d73b0ff7ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25.464646464646464"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1k6h9JXZHOsIzyVrt1PozuoewaeNRFS22",
      "authorship_tag": "ABX9TyMefsenb8A+js2McZ6fjN4o",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}